
train_dir=/home/c4ndypuff/Documentos/end2end-all-conv-master_copia/ddsm_train/TrainP
val_dir=/home/c4ndypuff/Documentos/end2end-all-conv-master_copia/ddsm_train/ValP
test_dir=/home/c4ndypuff/Documentos/end2end-all-conv-master_copia/ddsm_train/TestP

>>> Model training options: <<<
 {'patch_model_state': None, 'resume_from': '/home/c4ndypuff/Documentos/end2end-all-conv-master_copia/ddsm_train/ddsm_resnet50_s10_[512-512-1024]x2.h5', 'img_size': [1152, 896], 'img_scale': None, 'rescale_factor': 1.0, 'featurewise_center': True, 'featurewise_mean': 44.33, 'equalize_hist': False, 'batch_size': 4, 'train_bs_multiplier': 0.5, 'augmentation': True, 'class_list': ['neg', 'pos'], 'patch_net': 'resnet50', 'block_type': 'resnet', 'top_depths': [512, 512], 'top_repetitions': [2, 2], 'bottleneck_enlarge_factor': 2, 'add_heatmap': False, 'avg_pool_size': [7, 7], 'add_conv': True, 'add_shortcut': False, 'hm_strides': [1, 1], 'hm_pool_size': [5, 5], 'fc_init_units': 64, 'fc_layers': 2, 'top_layer_nb': None, 'nb_epoch': 0, 'all_layer_epochs': 30, 'load_val_ram': True, 'load_train_ram': False, 'weight_decay': 0.0005, 'hidden_dropout': 0.0, 'weight_decay2': 0.01, 'hidden_dropout2': 0.0, 'optim': 'adam', 'init_lr': 1e-05, 'lr_patience': 2, 'es_patience': 10, 'auto_batch_balance': True, 'pos_cls_weight': 4.0, 'neg_cls_weight': 1.0, 'all_layer_multiplier': 0.01, 'best_model': '/home/c4ndypuff/Documentos/end2end-all-conv-master_copia/ddsm_train/DDSM_settings3_lrch_5.h5', 'final_model': 'NOSAVE'} 

Create generator for train set
Found 5699 images belonging to 2 classes.
Create generator for val set
Found 654 images belonging to 2 classes.
Loading validation set into RAM.
Done.
Top layer nb = None
Start training on the top layers only

>>> AUROC was not scored. No model was saved. <<<
Done.
Start training on all layers
Epoch 1/30
 - Epoch:1, AUROC:[0.68168189 0.68168189], mean=0.6817

Learning Rate for Epoch 1: 9.999999747378752e-06

1660s - loss: 0.8368 - acc: 0.9007 - val_loss: 1.3482 - val_acc: 0.5902
Epoch 2/30
 - Epoch:2, AUROC:[0.63351397 0.63350022], mean=0.6335

Learning Rate for Epoch 2: 9.999999747378752e-06

1581s - loss: 0.7243 - acc: 0.9179 - val_loss: 1.4498 - val_acc: 0.6346
Epoch 3/30
 - Epoch:3, AUROC:[0.58276023 0.58276023], mean=0.5828

Learning Rate for Epoch 3: 9.999999747378752e-06

1582s - loss: 0.7226 - acc: 0.9068 - val_loss: 1.1578 - val_acc: 0.7370
Epoch 4/30
 - Epoch:4, AUROC:[0.61057163 0.61057163], mean=0.6106

Learning Rate for Epoch 4: 9.999999747378752e-06

1584s - loss: 0.7321 - acc: 0.9053 - val_loss: 1.0444 - val_acc: 0.6514
Epoch 5/30
 - Epoch:5, AUROC:[0.5331206 0.5331206], mean=0.5331

Learning Rate for Epoch 5: 9.999999747378752e-06

1581s - loss: 0.7143 - acc: 0.9025 - val_loss: 1.0718 - val_acc: 0.6713
Epoch 6/30
 - Epoch:6, AUROC:[0.58489217 0.58489217], mean=0.5849

Learning Rate for Epoch 6: 9.999999747378752e-06

1580s - loss: 0.7378 - acc: 0.8937 - val_loss: 1.0177 - val_acc: 0.7217
Epoch 7/30
 - Epoch:7, AUROC:[0.58881217 0.58881217], mean=0.5888

Learning Rate for Epoch 7: 9.999999747378752e-06

1581s - loss: 0.7095 - acc: 0.9004 - val_loss: 1.0434 - val_acc: 0.7003
Epoch 8/30
 - Epoch:8, AUROC:[0.59944432 0.59944432], mean=0.5994

Learning Rate for Epoch 8: 9.999999747378752e-06

1584s - loss: 0.6794 - acc: 0.9033 - val_loss: 1.0830 - val_acc: 0.7355
Epoch 9/30
 - Epoch:9, AUROC:[0.6262379 0.6262379], mean=0.6262

Learning Rate for Epoch 9: 9.999999747378752e-06

1582s - loss: 0.6830 - acc: 0.8986 - val_loss: 1.1352 - val_acc: 0.6636
Epoch 10/30
 - Epoch:10, AUROC:[0.56525088 0.56525088], mean=0.5653

Learning Rate for Epoch 10: 9.999999747378752e-06

1583s - loss: 0.6976 - acc: 0.8991 - val_loss: 1.1524 - val_acc: 0.6865
Epoch 11/30
 - Epoch:11, AUROC:[0.61545445 0.61545445], mean=0.6155

Learning Rate for Epoch 11: 4.999999873689376e-06

1582s - loss: 0.7842 - acc: 0.8644 - val_loss: 1.0665 - val_acc: 0.6835
Epoch 12/30
 - Epoch:12, AUROC:[0.61693992 0.61693992], mean=0.6169

Learning Rate for Epoch 12: 4.999999873689376e-06

1583s - loss: 0.7352 - acc: 0.8768 - val_loss: 1.0517 - val_acc: 0.6758
Epoch 13/30
 - Epoch:13, AUROC:[0.57934914 0.57934914], mean=0.5793

Learning Rate for Epoch 13: 4.999999873689376e-06

1582s - loss: 0.7237 - acc: 0.8779 - val_loss: 1.0176 - val_acc: 0.6911
Epoch 14/30
 - Epoch:14, AUROC:[0.55554027 0.55554027], mean=0.5555

Learning Rate for Epoch 14: 4.999999873689376e-06

1582s - loss: 0.7249 - acc: 0.8840 - val_loss: 1.1863 - val_acc: 0.7324
Epoch 15/30
 - Epoch:15, AUROC:[0.6020439  0.60255969], mean=0.6023

Learning Rate for Epoch 15: 4.999999873689376e-06

1582s - loss: 0.7363 - acc: 0.8725 - val_loss: 3.8864 - val_acc: 0.5872
Epoch 16/30
 - Epoch:16, AUROC:[0.58487841 0.58498845], mean=0.5849

Learning Rate for Epoch 16: 4.999999873689376e-06

1583s - loss: 0.7295 - acc: 0.8800 - val_loss: 2.3055 - val_acc: 0.5306
Epoch 17/30
 - Epoch:17, AUROC:[0.57130282 0.57130282], mean=0.5713

Learning Rate for Epoch 17: 4.999999873689376e-06

1582s - loss: 0.6874 - acc: 0.8925 - val_loss: 1.0861 - val_acc: 0.6758
Epoch 18/30
 - Epoch:18, AUROC:[0.62183649 0.62183649], mean=0.6218

Learning Rate for Epoch 18: 4.999999873689376e-06

1582s - loss: 0.7080 - acc: 0.8916 - val_loss: 0.9854 - val_acc: 0.6422
Epoch 19/30
 - Epoch:19, AUROC:[0.59925176 0.59925176], mean=0.5993

Learning Rate for Epoch 19: 4.999999873689376e-06

1582s - loss: 0.7166 - acc: 0.8868 - val_loss: 1.1348 - val_acc: 0.6239
